{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================\n",
    "# 1. データ前処理\n",
    "# ====================\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, user_seq, max_len):\n",
    "        self.user_seq = user_seq\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.user_seq[idx]\n",
    "        # Padding\n",
    "        seq = seq[-self.max_len:]\n",
    "        seq = [0] * (self.max_len - len(seq)) + seq\n",
    "        target = seq[-1]\n",
    "        input_seq = seq[:-1]\n",
    "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "\n",
    "def preprocess_movielens(max_len=50):\n",
    "    ratings = pd.read_csv(\n",
    "        os.path.join(Path().resolve(), \"datasets/ml-1m/ratings.dat\"),\n",
    "        sep=\"::\",\n",
    "        engine=\"python\",\n",
    "        header=None,\n",
    "        names=[\"uu_id\", \"movie_id\", \"rating\", \"timestamp\"],\n",
    "    )\n",
    "    ratings = ratings.sort_values(by=[\"uu_id\", \"timestamp\"])\n",
    "    user_seq = defaultdict(list)\n",
    "\n",
    "    for _, row in ratings.iterrows():\n",
    "        user_seq[row[\"uu_id\"]].append(row[\"movie_id\"])\n",
    "\n",
    "    user_seq = list(user_seq.values())\n",
    "\n",
    "    return user_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================\n",
    "# 2. SASRec モデル\n",
    "# ====================\n",
    "class SASRec(nn.Module):\n",
    "    def __init__(self, num_items, max_len, embed_dim, num_heads, num_layers, dropout):\n",
    "        super(SASRec, self).__init__()\n",
    "        self.num_items = num_items\n",
    "        self.max_len = max_len\n",
    "        self.embedding = nn.Embedding(num_items, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(max_len, embed_dim)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(embed_dim, num_heads, dim_feedforward=embed_dim * 4, dropout=dropout),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(embed_dim, num_items)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        seq_len = input_seq.size(1)\n",
    "        positions = torch.arange(seq_len, device=input_seq.device).unsqueeze(0)\n",
    "        item_embed = self.embedding(input_seq)\n",
    "        pos_embed = self.position_embedding(positions)\n",
    "        x = self.dropout(item_embed + pos_embed)\n",
    "        x = self.transformer(x)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ====================\n",
    "# 3. モデル学習と評価\n",
    "# ====================\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_seq, target in tqdm(dataloader, desc=\"Training\"):\n",
    "        input_seq, target = input_seq.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_seq)\n",
    "        logits = logits[:, -1, :]  # 最後の出力のみ\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for input_seq, target in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_seq, target = input_seq.to(device), target.to(device)\n",
    "            logits = model(input_seq)\n",
    "            logits = logits[:, -1, :]  # 最後の出力のみ\n",
    "            loss = criterion(logits, target)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_movielens() got multiple values for argument 'max_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# データ準備\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m user_seq \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_movielens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m train_seq, test_seq \u001b[38;5;241m=\u001b[39m train_test_split(user_seq, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     22\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m MovieLensDataset(train_seq, max_len\u001b[38;5;241m=\u001b[39mmax_len)\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_movielens() got multiple values for argument 'max_len'"
     ]
    }
   ],
   "source": [
    "\n",
    "# ====================\n",
    "# 4. ハイパーパラメータと実行\n",
    "# ====================\n",
    "def main():\n",
    "    # ハイパーパラメータ\n",
    "    data_path =  os.path.join(Path().resolve(), \"datasets/ml-1m/ratings.dat\")  # MovieLensデータのパス\n",
    "    \n",
    "    max_len = 50\n",
    "    embed_dim = 64\n",
    "    num_heads = 4\n",
    "    num_layers = 2\n",
    "    dropout = 0.2\n",
    "    batch_size = 128\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # データ準備\n",
    "    user_seq = preprocess_movielens(data_path, max_len=max_len)\n",
    "    train_seq, test_seq = train_test_split(user_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = MovieLensDataset(train_seq, max_len=max_len)\n",
    "    test_dataset = MovieLensDataset(test_seq, max_len=max_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    num_items = max(max(seq) for seq in user_seq) + 1\n",
    "\n",
    "    # モデル定義\n",
    "    model = SASRec(num_items, max_len, embed_dim, num_heads, num_layers, dropout).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 学習と評価\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss = evaluate(model, test_loader, criterion, device)\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
